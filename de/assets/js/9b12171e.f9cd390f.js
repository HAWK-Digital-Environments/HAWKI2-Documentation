"use strict";(self.webpackChunkdocs_site=self.webpackChunkdocs_site||[]).push([[705],{6869:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>i,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"HAWKI/Architecture/Model Connection","title":"Model Connection","description":"HAWKI Model Connection Data Flow","source":"@site/docs/HAWKI/3-Architecture/6-Model Connection.md","sourceDirName":"HAWKI/3-Architecture","slug":"/HAWKI/Architecture/Model Connection","permalink":"/HAWKI2-Documentation/de/HAWKI/Architecture/Model Connection","draft":false,"unlisted":false,"editUrl":"https://github.com/hawk/your-project/edit/main/docs/HAWKI/3-Architecture/6-Model Connection.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6},"sidebar":"HAWKI_Sidebar","previous":{"title":"Encryption","permalink":"/HAWKI2-Documentation/de/HAWKI/Architecture/Encryption"},"next":{"title":"Broadcasting","permalink":"/HAWKI2-Documentation/de/HAWKI/Architecture/Broadcasting"}}');var o=s(4848),t=s(8453);const i={sidebar_position:6},a=void 0,l={},d=[{value:"HAWKI Model Connection Data Flow",id:"hawki-model-connection-data-flow",level:2},{value:"Overview",id:"overview",level:2},{value:"Key Components",id:"key-components",level:2},{value:"Detailed Data Flow",id:"detailed-data-flow",level:2},{value:"1. Request Reception",id:"1-request-reception",level:3},{value:"2. Initial Payload Formatting",id:"2-initial-payload-formatting",level:3},{value:"Provider-Specific Formatting",id:"provider-specific-formatting",level:4},{value:"3. Request Handling Flow Determination",id:"3-request-handling-flow-determination",level:3},{value:"4. Connection to AI Model",id:"4-connection-to-ai-model",level:3},{value:"Non-Streaming Requests",id:"non-streaming-requests",level:4},{value:"Streaming Requests",id:"streaming-requests",level:4},{value:"5. Response Formatting",id:"5-response-formatting",level:3},{value:"For Non-Streaming Responses",id:"for-non-streaming-responses",level:4},{value:"For Streaming Responses",id:"for-streaming-responses",level:4},{value:"6. Usage Tracking",id:"6-usage-tracking",level:3},{value:"7. Response Delivery",id:"7-response-delivery",level:3},{value:"For Non-Streaming Responses",id:"for-non-streaming-responses-1",level:4},{value:"For Streaming Responses",id:"for-streaming-responses-1",level:4},{value:"For Group Chats",id:"for-group-chats",level:4},{value:"Provider-Specific Handling",id:"provider-specific-handling",level:2},{value:"OpenAI/GWDG Format",id:"openaigwdg-format",level:3},{value:"Google Format",id:"google-format",level:3},{value:"Error Handling",id:"error-handling",level:2}];function c(e){const n={code:"code",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h2,{id:"hawki-model-connection-data-flow",children:"HAWKI Model Connection Data Flow"}),"\n",(0,o.jsxs)(n.p,{children:["This section describes the data flow in HAWKI's AI model connection system, from the moment a request is received in the ",(0,o.jsx)(n.code,{children:"StreamController->handleAiConnectionRequest"})," method, through the formatting of data for AI models, to how the model responses are processed and formatted for HAWKI."]}),"\n",(0,o.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,o.jsx)(n.p,{children:"HAWKI's AI integration uses a service-based architecture to process requests to various AI models (OpenAI, GWDG, Google). The system is designed to handle both streaming and non-streaming responses, and supports different AI providers with their specific API requirements."}),"\n",(0,o.jsx)(n.h2,{id:"key-components",children:"Key Components"}),"\n",(0,o.jsx)(n.p,{children:"The AI connection system consists of several key services:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"StreamController"}),": Entry point for AI requests handling both direct and group chat interactions"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"AiPayloadFormatterService"}),": Formats user messages into provider-specific payloads"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"ModelConnectionService"}),": Manages the HTTP connections to AI model providers"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"AiResponseFormatterService"}),": Processes and formats responses from AI models"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"ModelUtilityService"}),": Provides utility functions for model configuration and provider detection"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"UsageAnalyzerService"}),": Tracks and records token usage for analytics and billing"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"detailed-data-flow",children:"Detailed Data Flow"}),"\n",(0,o.jsx)(n.h3,{id:"1-request-reception",children:"1. Request Reception"}),"\n",(0,o.jsxs)(n.p,{children:["The flow begins when a client sends a request to the ",(0,o.jsx)(n.code,{children:"handleAiConnectionRequest"})," method in the ",(0,o.jsx)(n.code,{children:"StreamController"}),". The request includes:"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"A payload containing the model ID, streaming preference, and messages"}),"\n",(0,o.jsx)(n.li,{children:"Additional metadata for handling the response (broadcast flags, message IDs, etc.)"}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-php",children:"$validatedData = $request->validate([\n    'payload.model' => 'required|string',\n    'payload.stream' => 'required|boolean',\n    'payload.messages' => 'required|array',\n    'payload.messages.*.role' => 'required|string',\n    'payload.messages.*.content' => 'required|array',\n    'payload.messages.*.content.text' => 'required|string',\n    \n    'broadcast' => 'required|boolean',\n    'isUpdate' => 'nullable|boolean',\n    'messageId' => 'nullable|string',\n    'threadIndex' => 'nullable|int', \n    'slug' => 'nullable|string',\n    'key' => 'nullable|string',\n]);\n"})}),"\n",(0,o.jsx)(n.h3,{id:"2-initial-payload-formatting",children:"2. Initial Payload Formatting"}),"\n",(0,o.jsxs)(n.p,{children:["The received request is passed to the ",(0,o.jsx)(n.code,{children:"AiPayloadFormatterService"})," which formats the messages for the appropriate AI provider:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-js",children:"$formattedPayload = $this->payloadFormatter->formatPayload($validatedData['payload']);\n"})}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"formatPayload"})," method:"]}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Identifies the provider based on the model ID"}),"\n",(0,o.jsx)(n.li,{children:"Applies provider-specific formatting rules"}),"\n",(0,o.jsx)(n.li,{children:"Returns a properly formatted payload that matches the provider's API requirements"}),"\n"]}),"\n",(0,o.jsx)(n.h4,{id:"provider-specific-formatting",children:"Provider-Specific Formatting"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"For OpenAI/GWDG:"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Handles special cases for models like mixtral-8x7b-instruct and o1"}),"\n",(0,o.jsx)(n.li,{children:"Extracts the text content from the nested content structure"}),"\n",(0,o.jsx)(n.li,{children:"Returns a payload with model, messages, and stream parameters"}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-js",children:"return [\n    'model' => $payload['model'],\n    'messages' => $formattedMessages,\n    'stream' => $payload['stream'],\n];\n"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"For Google:"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Transforms role names (assistant \u2192 model)"}),"\n",(0,o.jsx)(n.li,{children:'Restructures the content into Google\'s expected "parts" format'}),"\n",(0,o.jsx)(n.li,{children:"Returns a payload with model, contents, and stream parameters"}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-js",children:"return [\n    'model' => $payload['model'],\n    'contents' => $formattedMessages,\n    'stream' => true,\n];\n"})}),"\n",(0,o.jsx)(n.h3,{id:"3-request-handling-flow-determination",children:"3. Request Handling Flow Determination"}),"\n",(0,o.jsxs)(n.p,{children:["Based on the ",(0,o.jsx)(n.code,{children:"broadcast"})," flag, the request flows through one of two paths:"]}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Group Chat Path"})," (",(0,o.jsx)(n.code,{children:"handleGroupChatRequest"}),"): For messages that need to be broadcasted to a room"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Direct Path"}),": For one-on-one AI conversations"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"The system also checks if the model supports streaming:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-js",children:"if($formattedPayload['stream'] && $model['streamable']){\n    $formattedPayload['stream_options'] = [\n        \"include_usage\"=> true,\n    ];\n    $this->createStream($formattedPayload);\n}\nelse{\n    $data = $this->createRequest($formattedPayload);\n    return response()->json($data);\n}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"4-connection-to-ai-model",children:"4. Connection to AI Model"}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"ModelConnectionService"})," handles the actual HTTP connection to the AI provider's API:"]}),"\n",(0,o.jsx)(n.h4,{id:"non-streaming-requests",children:"Non-Streaming Requests"}),"\n",(0,o.jsxs)(n.p,{children:["For non-streaming requests, ",(0,o.jsx)(n.code,{children:"requestToAiModel"})," or ",(0,o.jsx)(n.code,{children:"requestToGoogle"})," methods:"]}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Set up the necessary HTTP headers"}),"\n",(0,o.jsx)(n.li,{children:"Retrieve the provider configuration"}),"\n",(0,o.jsx)(n.li,{children:"Create a cURL request with the formatted payload"}),"\n",(0,o.jsx)(n.li,{children:"Send the request to the provider's API endpoint"}),"\n",(0,o.jsx)(n.li,{children:"Return the complete response"}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-js",children:"$response = $this->modelConnection->requestToAiModel($formattedPayload);\n"})}),"\n",(0,o.jsx)(n.h4,{id:"streaming-requests",children:"Streaming Requests"}),"\n",(0,o.jsxs)(n.p,{children:["For streaming responses, the ",(0,o.jsx)(n.code,{children:"streamToAiModel"})," method:"]}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Sets up SSE (Server-Sent Events) headers"}),"\n",(0,o.jsx)(n.li,{children:"Configures a persistent cURL connection"}),"\n",(0,o.jsx)(n.li,{children:"Uses a callback function to process each chunk as it arrives"}),"\n",(0,o.jsx)(n.li,{children:"Maintains the connection until the response is complete"}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-js",children:"$this->modelConnection->streamToAiModel($formattedPayload, $onData);\n"})}),"\n",(0,o.jsx)(n.p,{children:"The callback function handles each chunk of data:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-js",children:"$onData = function ($data) use ($user, $avatar_url, $formattedPayload) {\n    // Process chunks and send to client\n};\n"})}),"\n",(0,o.jsx)(n.h3,{id:"5-response-formatting",children:"5. Response Formatting"}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"AiResponseFormatterService"})," processes responses from the AI models:"]}),"\n",(0,o.jsx)(n.h4,{id:"for-non-streaming-responses",children:"For Non-Streaming Responses"}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"formatDefaultResponse"})," or ",(0,o.jsx)(n.code,{children:"formatGoogleResponse"})," methods:"]}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Parse the JSON response"}),"\n",(0,o.jsx)(n.li,{children:"Extract the content and usage information"}),"\n",(0,o.jsx)(n.li,{children:"Return the content and usage as an array"}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-js",children:"[$content, $usage] = $this->responseFormatter->formatDefaultResponse($response);\n"})}),"\n",(0,o.jsx)(n.h4,{id:"for-streaming-responses",children:"For Streaming Responses"}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"formatDefaultChunk"})," method:"]}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Parses each JSON chunk"}),"\n",(0,o.jsx)(n.li,{children:"Checks if it's the final chunk"}),"\n",(0,o.jsx)(n.li,{children:"Extracts usage information if available"}),"\n",(0,o.jsx)(n.li,{children:"Returns the content fragment, completion status, and usage data"}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-js",children:"[$chunk, $isDone, $usage] = $this->responseFormatter->formatDefaultChunk($chunk);\n"})}),"\n",(0,o.jsx)(n.h3,{id:"6-usage-tracking",children:"6. Usage Tracking"}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"UsageAnalyzerService"})," records token usage for analytics and billing:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-js",children:"$this->usageAnalyzer->submitUsageRecord($usage, 'private', $formattedPayload['model']);\n"})}),"\n",(0,o.jsx)(n.p,{children:"This records:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Prompt and completion tokens"}),"\n",(0,o.jsx)(n.li,{children:"Model used"}),"\n",(0,o.jsx)(n.li,{children:"Type of conversation (private or group)"}),"\n",(0,o.jsx)(n.li,{children:"User and room information (if applicable)"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"7-response-delivery",children:"7. Response Delivery"}),"\n",(0,o.jsx)(n.p,{children:"Finally, the formatted response is delivered to the client:"}),"\n",(0,o.jsx)(n.h4,{id:"for-non-streaming-responses-1",children:"For Non-Streaming Responses"}),"\n",(0,o.jsx)(n.p,{children:"A complete JSON response is returned:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-js",children:"$messageData = [\n    'author' => [\n        'username' => $user->username,\n        'name' => $user->name,\n        'avatar_url' => $avatar_url,\n    ],\n    'model' => $formattedPayload['model'],\n    'isDone' => true,\n    'content' => $content,\n];\nreturn $messageData;\n"})}),"\n",(0,o.jsx)(n.h4,{id:"for-streaming-responses-1",children:"For Streaming Responses"}),"\n",(0,o.jsx)(n.p,{children:"Each chunk is immediately sent to the client:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-js",children:'echo json_encode($messageData). "\\n";\n'})}),"\n",(0,o.jsx)(n.h4,{id:"for-group-chats",children:"For Group Chats"}),"\n",(0,o.jsx)(n.p,{children:"In group chat mode, the response is:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Encrypted with the room's key"}),"\n",(0,o.jsx)(n.li,{children:"Stored in the database"}),"\n",(0,o.jsx)(n.li,{children:"Broadcasted to all members via Laravel events"}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-js",children:"$encryptiedData = $cryptoController->encryptWithSymKey($encKey, $content, false);\n\n$message = Message::create([\n    'room_id' => $room->id,\n    'member_id' => $member->id,\n    'message_id' => $nextMessageId,\n    'message_role' => 'assistant',\n    'model' => $formattedPayload['model'],\n    'iv' => $encryptiedData['iv'],\n    'tag' => $encryptiedData['tag'],\n    'content' => $encryptiedData['ciphertext'],\n]);\n\nSendMessage::dispatch($message, $isUpdate)->onQueue('message_broadcast');\n"})}),"\n",(0,o.jsx)(n.h2,{id:"provider-specific-handling",children:"Provider-Specific Handling"}),"\n",(0,o.jsx)(n.h3,{id:"openaigwdg-format",children:"OpenAI/GWDG Format"}),"\n",(0,o.jsx)(n.p,{children:"Input message format:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-json",children:'{\n  "model": "gpt-4o",\n  "messages": [\n    {"role": "system", "content": "You are a helpful assistant."},\n    {"role": "user", "content": "Hello, how are you?"}\n  ],\n  "stream": true\n}\n'})}),"\n",(0,o.jsx)(n.p,{children:"Response format:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-json",children:'{\n  "choices": [\n    {\n      "delta": {\n        "content": "I\'m doing well, thank you for asking!"\n      },\n      "finish_reason": "stop"\n    }\n  ],\n  "usage": {\n    "prompt_tokens": 23,\n    "completion_tokens": 12\n  }\n}\n'})}),"\n",(0,o.jsx)(n.h3,{id:"google-format",children:"Google Format"}),"\n",(0,o.jsx)(n.p,{children:"Input message format:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-json",children:'{\n  "contents": [\n    {\n      "role": "user",\n      "parts": {\n        "text": "Hello, how are you?"\n      }\n    }\n  ]\n}\n'})}),"\n",(0,o.jsx)(n.p,{children:"Response format:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-json",children:'{\n  "candidates": [\n    {\n      "content": {\n        "parts": [\n          {\n            "text": "I\'m doing well, thank you for asking!"\n          }\n        ]\n      }\n    }\n  ],\n  "usageMetadata": {\n    "promptTokenCount": 23,\n    "candidatesTokenCount": 12\n  }\n}\n'})}),"\n",(0,o.jsx)(n.h2,{id:"error-handling",children:"Error Handling"}),"\n",(0,o.jsx)(n.p,{children:"The system includes error handling at multiple levels:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Request validation in the controller"}),"\n",(0,o.jsx)(n.li,{children:"Provider availability checking in the formatter"}),"\n",(0,o.jsx)(n.li,{children:"Connection error handling in the model connection service"}),"\n",(0,o.jsx)(n.li,{children:"Response parsing error handling in the formatter"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"When errors occur, they are logged and appropriate error responses are returned to the client."})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>i,x:()=>a});var r=s(6540);const o={},t=r.createContext(o);function i(e){const n=r.useContext(t);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),r.createElement(t.Provider,{value:n},e.children)}}}]);